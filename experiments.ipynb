{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725e6754",
   "metadata": {},
   "source": [
    "# Building an Entity Normalization Engine\n",
    "\n",
    "This notebook contains experiments in an attempt to build an entity normalization engine. The input to this engine is short strings that could encompass the following entities: company names, company addresses, serial numbers, physical goods and locations.\n",
    "\n",
    "The task is divided into 2 parts:\n",
    "\n",
    "**Part 1**: Build a system that can identify unique entities for each category above. Some of these will be trivial (remove spaces, edit distance) while others are more complicated and will need a trained model / some other form of knowledge and guidance.\n",
    "\n",
    "**Part 2**: Build a system that receives strings one by one and groups together any entities that have passed through the system previously. Check the latest sample received, scan the entries already received, identify if the entity is a duplicate and then add it to a cluster / create a new cluster depending on the result.\n",
    "\n",
    "Here are fictional examples of the strings we will be dealing with:\n",
    "\n",
    "- Company names: “Marks and Spencers Ltd”, “M&S Limited”, “NVIDIA Ireland”\n",
    "- Company addresses: “SLOUGH SE12 2XY”, “33 TIMBER YARD, LONDON, L1 8XY”, “44 CHINA ROAD, KOWLOON, HONG KONG”\n",
    "- Serial numbers: “XYZ 13423 / ILD”, “ABC/ICL/20891NC”\n",
    "- Physical Goods: “HARDWOOD TABLE”, “PLASTIC BOTTLE”\n",
    "- Locations: “LONDON”, “HONG KONG”, “ASIA”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18efec46",
   "metadata": {},
   "source": [
    "## Part 1: Category-Specific Normalization Engines\n",
    "\n",
    "The general, theoretical approach here is:\n",
    "\n",
    "*Step 1* - Text preprocessing: standardizing lettercase, punctuation, whitespace, accented/special characters, legal control terms (Ltd, Co, etc) depending on which category we are dealing with\n",
    "\n",
    "*Step 2* - Entity clustering: use string_grouper library that uses TF-IDF (Term Frequency multiplied by Inverse Document Frequency) with N-Grams to calculate cosine similarities within a single Series of strings and groups them by assigning to each string one string from the group chosen as the group-representative for each group of similar strings found.\n",
    "\n",
    "The code for both these steps will vary depending on the category we are dealing with. We can address the categories one by one in ascending order of difficulty. Functions are created for each in order to copy them to python scripts efficiently.\n",
    "\n",
    "*Note: Original idea was to create for each category string similarity matrix with similarity metric such as levenshtein distance, Jaro-Winkler or caverphone algorithm. Next, use clustering algorithm to cluster entities; affinity propagation seems to be standard for this task. For each unique entity (cluster) assign substring with the longest string length as the standard name for that cluster. I experimented with these approach but found the chosen approach to be quicker to execute, more legible and have better performance.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b1dc5",
   "metadata": {},
   "source": [
    "### Serial Numbers\n",
    "\n",
    "We expect minimal pre-processing to be done for serial numbers and rely on a very high similarity threshold for matching strings. It's actually better to just group the strings directly after pre-processing, but we might as well just use the string grouper function to keep the process standard for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8750067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample df for serial numbers from manually generated list\n",
    "serial_nums = [\"XYZ 13423 / ILD\", \"ABC/ICL/20891NC\", \"XYZ-13423-ILD\", \"ABCICL-20891NC\", \"XYZ 14 / IKR\", \"DNC/ICL/20891NC\", \"XYK-13423-ILD\"]\n",
    "df_serial_nums = pd.DataFrame(serial_nums, columns=['serial_nums'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c546fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XYZ 13423 / ILD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC/ICL/20891NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XYZ-13423-ILD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCICL-20891NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XYZ 14 / IKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DNC/ICL/20891NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XYK-13423-ILD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       serial_nums\n",
       "0  XYZ 13423 / ILD\n",
       "1  ABC/ICL/20891NC\n",
       "2    XYZ-13423-ILD\n",
       "3   ABCICL-20891NC\n",
       "4     XYZ 14 / IKR\n",
       "5  DNC/ICL/20891NC\n",
       "6    XYK-13423-ILD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_serial_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd5eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# remove special characters function\n",
    "def remove_special_characters(text):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# preprocess function for dataframe of serial numbers - provide dataframe and column name for serial nums as input\n",
    "def preprocess_serial_nums(dataframe, column_name):\n",
    "    clean_list = [remove_special_characters(text) for text in dataframe[column_name]] \n",
    "    clean_list = [text.lower() for text in clean_list]\n",
    "    clean_list = [text.replace(' ', '') for text in clean_list] # remove all whitespaces\n",
    "    df_clean_serial_nums = pd.DataFrame(np.column_stack([dataframe[column_name], clean_list]), columns=['serial_nums', 'clean_serial_nums'])\n",
    "    return df_clean_serial_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cbbcc5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_nums</th>\n",
       "      <th>clean_serial_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XYZ 13423 / ILD</td>\n",
       "      <td>xyz13423ild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC/ICL/20891NC</td>\n",
       "      <td>abcicl20891nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XYZ-13423-ILD</td>\n",
       "      <td>xyz13423ild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCICL-20891NC</td>\n",
       "      <td>abcicl20891nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XYZ 14 / IKR</td>\n",
       "      <td>xyz14ikr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DNC/ICL/20891NC</td>\n",
       "      <td>dncicl20891nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XYK-13423-ILD</td>\n",
       "      <td>xyk13423ild</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       serial_nums clean_serial_nums\n",
       "0  XYZ 13423 / ILD       xyz13423ild\n",
       "1  ABC/ICL/20891NC     abcicl20891nc\n",
       "2    XYZ-13423-ILD       xyz13423ild\n",
       "3   ABCICL-20891NC     abcicl20891nc\n",
       "4     XYZ 14 / IKR          xyz14ikr\n",
       "5  DNC/ICL/20891NC     dncicl20891nc\n",
       "6    XYK-13423-ILD       xyk13423ild"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_serial_nums_cleaned = preprocess_serial_nums(df_serial_nums, 'serial_nums'); df_serial_nums_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5767f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string_grouper import group_similar_strings\n",
    "\n",
    "# entity matching function for dataframe created at preprocessing stage - provide dataframe and original column name for serial nums\n",
    "def entity_matcher_serial_nums(dataframe, column_name):\n",
    "    # group entities using tf-idf to calculate cosine similarities - look for 99% minimum similarity\n",
    "    dataframe[['unique_entity_ID', 'unique_entity']] = group_similar_strings(dataframe['clean_serial_nums'], min_similarity = 0.99)\n",
    "    dataframe = dataframe.groupby(['unique_entity_ID', 'unique_entity'])[column_name].apply('; '.join).reset_index()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3cd0aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>serial_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>xyz13423ild</td>\n",
       "      <td>XYZ 13423 / ILD; XYZ-13423-ILD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abcicl20891nc</td>\n",
       "      <td>ABC/ICL/20891NC; ABCICL-20891NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>xyz14ikr</td>\n",
       "      <td>XYZ 14 / IKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>dncicl20891nc</td>\n",
       "      <td>DNC/ICL/20891NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>xyk13423ild</td>\n",
       "      <td>XYK-13423-ILD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID  unique_entity                      serial_nums\n",
       "0                 0    xyz13423ild   XYZ 13423 / ILD; XYZ-13423-ILD\n",
       "1                 1  abcicl20891nc  ABC/ICL/20891NC; ABCICL-20891NC\n",
       "2                 4       xyz14ikr                     XYZ 14 / IKR\n",
       "3                 5  dncicl20891nc                  DNC/ICL/20891NC\n",
       "4                 6    xyk13423ild                    XYK-13423-ILD"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_entities_serial_nums = entity_matcher_serial_nums(df_serial_nums_cleaned, 'serial_nums'); df_unique_entities_serial_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5bb7795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# function for processing df of serial numbers and clustering them using string similarity\n",
    "def clustering_serial_nums(dataframe, column_name):\n",
    "    # preprocess dataframe\n",
    "    df_serial_nums_cleaned = preprocess_serial_nums(dataframe, column_name)\n",
    "    # start clustering of serial nums\n",
    "    print('Entity clustering will start now.')\n",
    "    start = time.time()\n",
    "    df_unique_entities_serial_nums = entity_matcher_serial_nums(df_serial_nums_cleaned, column_name)\n",
    "    time.sleep(1)\n",
    "    end = time.time()\n",
    "    # print total time taken\n",
    "    print(f\"Runtime of the program is {end - start} seconds.\")\n",
    "    # create csv with timestamp\n",
    "    current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = 'serial_num_normalized' + str(current_time) + '.csv'\n",
    "    # print job status\n",
    "    print(f\"{filename} has been saved in current directory.\")\n",
    "    return df_unique_entities_serial_nums.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1be7c59d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity clustering will start now.\n",
      "Runtime of the program is 1.0202109813690186 seconds.\n",
      "serial_num_normalized20210725-235347.csv has been saved in current directory.\n"
     ]
    }
   ],
   "source": [
    "clustering_serial_nums(df_serial_nums, 'serial_nums')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84bce05d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>serial_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>xyz13423ild</td>\n",
       "      <td>XYZ 13423 / ILD; XYZ-13423-ILD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abcicl20891nc</td>\n",
       "      <td>ABC/ICL/20891NC; ABCICL-20891NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>xyz14ikr</td>\n",
       "      <td>XYZ 14 / IKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>dncicl20891nc</td>\n",
       "      <td>DNC/ICL/20891NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>xyk13423ild</td>\n",
       "      <td>XYK-13423-ILD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID  unique_entity                      serial_nums\n",
       "0                 0    xyz13423ild   XYZ 13423 / ILD; XYZ-13423-ILD\n",
       "1                 1  abcicl20891nc  ABC/ICL/20891NC; ABCICL-20891NC\n",
       "2                 4       xyz14ikr                     XYZ 14 / IKR\n",
       "3                 5  dncicl20891nc                  DNC/ICL/20891NC\n",
       "4                 6    xyk13423ild                    XYK-13423-ILD"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect results\n",
    "pd.read_csv('serial_num_normalized20210725-235347.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35205db5",
   "metadata": {},
   "source": [
    "### Company Addresses\n",
    "\n",
    "This category is actually quite tricky, but we won't attempt to dive too deep into it for this exercise. We can simplify things and pretend that addresses can be addressed similarly to serial numbers. In reality address parsing and normalization is extremely tricky especially because even the simplest addresses are packed with local conventions, abbreviations and context. If we had to address this head-on we would use the [libpostal](https://github.com/openvenues/libpostal) library. It converts free-form addresses that humans use into clean normalized forms suitable for machine comparison and full-text indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11bee4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample df for addresses from manually generated list\n",
    "addresses = [\"SLOUGH SE12 2XY\", \"33 TIMBER YARD, LONDON, L1 8XY\", \"44 CHINA ROAD, KOWLOON, HONG KONG\", \"33, TIMBER YARD, LONDON, L1 8XY\"]\n",
    "df_addresses = pd.DataFrame(addresses, columns=['addresses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8bed0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addresses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLOUGH SE12 2XY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33 TIMBER YARD, LONDON, L1 8XY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44 CHINA ROAD, KOWLOON, HONG KONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33, TIMBER YARD, LONDON, L1 8XY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           addresses\n",
       "0                    SLOUGH SE12 2XY\n",
       "1     33 TIMBER YARD, LONDON, L1 8XY\n",
       "2  44 CHINA ROAD, KOWLOON, HONG KONG\n",
       "3    33, TIMBER YARD, LONDON, L1 8XY"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b1fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function for dataframe of addresses - provide dataframe and column name for addresses as input\n",
    "def preprocess_addresses(dataframe, column_name):\n",
    "    clean_list = [remove_special_characters(text) for text in dataframe[column_name]] \n",
    "    clean_list = [text.lower() for text in clean_list]\n",
    "    clean_list = [text.replace('  ', ' ') for text in clean_list] # remove extra whitespaces\n",
    "    clean_list = [text.strip() for text in clean_list]\n",
    "    df_clean_addresses = pd.DataFrame(np.column_stack([dataframe[column_name], clean_list]), columns=['addresses', 'clean_addresses'])\n",
    "    return df_clean_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea49d7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addresses</th>\n",
       "      <th>clean_addresses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLOUGH SE12 2XY</td>\n",
       "      <td>slough se12 2xy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33 TIMBER YARD, LONDON, L1 8XY</td>\n",
       "      <td>33 timber yard london l1 8xy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44 CHINA ROAD, KOWLOON, HONG KONG</td>\n",
       "      <td>44 china road kowloon hong kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33, TIMBER YARD, LONDON, L1 8XY</td>\n",
       "      <td>33 timber yard london l1 8xy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           addresses                  clean_addresses\n",
       "0                    SLOUGH SE12 2XY                  slough se12 2xy\n",
       "1     33 TIMBER YARD, LONDON, L1 8XY     33 timber yard london l1 8xy\n",
       "2  44 CHINA ROAD, KOWLOON, HONG KONG  44 china road kowloon hong kong\n",
       "3    33, TIMBER YARD, LONDON, L1 8XY     33 timber yard london l1 8xy"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_addresses_cleaned = preprocess_addresses(df_addresses, 'addresses'); df_addresses_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53e8ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity matching function for dataframe created at preprocessing stage - provide dataframe and original column name for addresses\n",
    "def entity_matcher_addresses(dataframe, column_name):\n",
    "    # group entities using tf-idf to calculate cosine similarities - look for 99% minimum similarity\n",
    "    dataframe[['unique_entity_ID', 'unique_entity']] = group_similar_strings(dataframe['clean_addresses'], min_similarity = 0.99)\n",
    "    dataframe = dataframe.groupby(['unique_entity_ID', 'unique_entity'])[column_name].apply('; '.join).reset_index()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a74722ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>addresses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>slough se12 2xy</td>\n",
       "      <td>SLOUGH SE12 2XY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33 timber yard london l1 8xy</td>\n",
       "      <td>33 TIMBER YARD, LONDON, L1 8XY; 33, TIMBER YAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>44 china road kowloon hong kong</td>\n",
       "      <td>44 CHINA ROAD, KOWLOON, HONG KONG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID                    unique_entity  \\\n",
       "0                 0                  slough se12 2xy   \n",
       "1                 1     33 timber yard london l1 8xy   \n",
       "2                 2  44 china road kowloon hong kong   \n",
       "\n",
       "                                           addresses  \n",
       "0                                    SLOUGH SE12 2XY  \n",
       "1  33 TIMBER YARD, LONDON, L1 8XY; 33, TIMBER YAR...  \n",
       "2                  44 CHINA ROAD, KOWLOON, HONG KONG  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_entities_addresses = entity_matcher_addresses(df_addresses_cleaned, 'addresses'); df_unique_entities_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46837ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for processing df of addresses and clustering them using string similarity\n",
    "def clustering_addresses(dataframe, column_name):\n",
    "    # preprocess dataframe\n",
    "    df_addresses_cleaned = preprocess_addresses(dataframe, column_name)\n",
    "    # start clustering of addresses\n",
    "    print('Entity clustering will start now.')\n",
    "    start = time.time()\n",
    "    df_unique_entities_addresses = entity_matcher_addresses(df_addresses_cleaned, column_name)\n",
    "    time.sleep(1)\n",
    "    end = time.time()\n",
    "    # print total time taken\n",
    "    print(f\"Runtime of the program is {end - start} seconds.\")\n",
    "    # create csv with timestamp\n",
    "    current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = 'addresses_normalized' + str(current_time) + '.csv'\n",
    "    # print job status\n",
    "    print(f\"{filename} has been saved in current directory.\")\n",
    "    return df_unique_entities_addresses.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64a0a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity clustering will start now.\n",
      "Runtime of the program is 1.0151150226593018 seconds.\n",
      "addresses_normalized20210725-235415.csv has been saved in current directory.\n"
     ]
    }
   ],
   "source": [
    "clustering_addresses(df_addresses, 'addresses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c2e7eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>addresses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>slough se12 2xy</td>\n",
       "      <td>SLOUGH SE12 2XY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33 timber yard london l1 8xy</td>\n",
       "      <td>33 TIMBER YARD, LONDON, L1 8XY; 33, TIMBER YAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>44 china road kowloon hong kong</td>\n",
       "      <td>44 CHINA ROAD, KOWLOON, HONG KONG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID                    unique_entity  \\\n",
       "0                 0                  slough se12 2xy   \n",
       "1                 1     33 timber yard london l1 8xy   \n",
       "2                 2  44 china road kowloon hong kong   \n",
       "\n",
       "                                           addresses  \n",
       "0                                    SLOUGH SE12 2XY  \n",
       "1  33 TIMBER YARD, LONDON, L1 8XY; 33, TIMBER YAR...  \n",
       "2                  44 CHINA ROAD, KOWLOON, HONG KONG  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect results\n",
    "pd.read_csv('addresses_normalized20210725-235415.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86db31d",
   "metadata": {},
   "source": [
    "### Physical Goods\n",
    "\n",
    "For this category we can start using similarity thresholds that are lower. We start getting into entities that would make more sense to use a language model with. We'll stick with the TF-IDF cosine similarity approach for the sake of this exercise and see if it does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d2978bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample df for physical goods from manually generated list\n",
    "goods = [\"HARDWOOD TABLE\", \"PLASTIC BOTTLE\", \"TOYS\", \"plastic water bottle\", \"Wooden Table\", \"ALUMINIUM TABLE\"]\n",
    "df_goods = pd.DataFrame(goods, columns=['goods'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d3d2aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HARDWOOD TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLASTIC BOTTLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plastic water bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wooden Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALUMINIUM TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  goods\n",
       "0        HARDWOOD TABLE\n",
       "1        PLASTIC BOTTLE\n",
       "2                  TOYS\n",
       "3  plastic water bottle\n",
       "4          Wooden Table\n",
       "5       ALUMINIUM TABLE"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15257332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function for dataframe of goods - provide dataframe and column name for goods as input\n",
    "def preprocess_goods(dataframe, column_name):\n",
    "    clean_list = [remove_special_characters(text) for text in dataframe[column_name]] \n",
    "    clean_list = [text.lower() for text in clean_list]\n",
    "    clean_list = [text.replace('  ', ' ') for text in clean_list] # remove extra whitespaces\n",
    "    clean_list = [text.strip() for text in clean_list]\n",
    "    df_clean_goods = pd.DataFrame(np.column_stack([dataframe[column_name], clean_list]), columns=['goods', 'clean_goods'])\n",
    "    return df_clean_goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8acc74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goods</th>\n",
       "      <th>clean_goods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HARDWOOD TABLE</td>\n",
       "      <td>hardwood table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLASTIC BOTTLE</td>\n",
       "      <td>plastic bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOYS</td>\n",
       "      <td>toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plastic water bottle</td>\n",
       "      <td>plastic water bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wooden Table</td>\n",
       "      <td>wooden table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALUMINIUM TABLE</td>\n",
       "      <td>aluminium table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  goods           clean_goods\n",
       "0        HARDWOOD TABLE        hardwood table\n",
       "1        PLASTIC BOTTLE        plastic bottle\n",
       "2                  TOYS                  toys\n",
       "3  plastic water bottle  plastic water bottle\n",
       "4          Wooden Table          wooden table\n",
       "5       ALUMINIUM TABLE       aluminium table"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_goods_cleaned = preprocess_goods(df_goods, 'goods'); df_goods_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48d4a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity matching function for dataframe created at preprocessing stage - provide dataframe and original column name for goods\n",
    "def entity_matcher_goods(dataframe, column_name):\n",
    "    # group entities using tf-idf to calculate cosine similarities - look for 30% minimum similarity\n",
    "    dataframe[['unique_entity_ID', 'unique_entity']] = group_similar_strings(dataframe['clean_goods'], min_similarity = 0.3)\n",
    "    dataframe = dataframe.groupby(['unique_entity_ID', 'unique_entity'])[column_name].apply('; '.join).reset_index()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3265c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>goods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hardwood table</td>\n",
       "      <td>HARDWOOD TABLE; Wooden Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>plastic bottle</td>\n",
       "      <td>PLASTIC BOTTLE; plastic water bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>toys</td>\n",
       "      <td>TOYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>aluminium table</td>\n",
       "      <td>ALUMINIUM TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID    unique_entity                                 goods\n",
       "0                 0   hardwood table          HARDWOOD TABLE; Wooden Table\n",
       "1                 1   plastic bottle  PLASTIC BOTTLE; plastic water bottle\n",
       "2                 2             toys                                  TOYS\n",
       "3                 5  aluminium table                       ALUMINIUM TABLE"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_entities_goods = entity_matcher_goods(df_goods_cleaned, 'goods'); df_unique_entities_goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad4e3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for processing df of goods and clustering them using string similarity\n",
    "def clustering_goods(dataframe, column_name):\n",
    "    # preprocess dataframe\n",
    "    df_goods_cleaned = preprocess_goods(dataframe, column_name)\n",
    "    # start clustering of goods\n",
    "    print('Entity clustering will start now.')\n",
    "    start = time.time()\n",
    "    df_unique_entities_goods = entity_matcher_goods(df_goods_cleaned, column_name)\n",
    "    time.sleep(1)\n",
    "    end = time.time()\n",
    "    # print total time taken\n",
    "    print(f\"Runtime of the program is {end - start} seconds.\")\n",
    "    # create csv with timestamp\n",
    "    current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = 'goods_normalized' + str(current_time) + '.csv'\n",
    "    # print job status\n",
    "    print(f\"{filename} has been saved in current directory.\")\n",
    "    return df_unique_entities_goods.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50d82008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity clustering will start now.\n",
      "Runtime of the program is 1.0178301334381104 seconds.\n",
      "goods_normalized20210725-235445.csv has been saved in current directory.\n"
     ]
    }
   ],
   "source": [
    "clustering_goods(df_goods, 'goods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f59683d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>goods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hardwood table</td>\n",
       "      <td>HARDWOOD TABLE; Wooden Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>plastic bottle</td>\n",
       "      <td>PLASTIC BOTTLE; plastic water bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>toys</td>\n",
       "      <td>TOYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>aluminium table</td>\n",
       "      <td>ALUMINIUM TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID    unique_entity                                 goods\n",
       "0                 0   hardwood table          HARDWOOD TABLE; Wooden Table\n",
       "1                 1   plastic bottle  PLASTIC BOTTLE; plastic water bottle\n",
       "2                 2             toys                                  TOYS\n",
       "3                 5  aluminium table                       ALUMINIUM TABLE"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect results\n",
    "pd.read_csv('goods_normalized20210725-235445.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e8d16a",
   "metadata": {},
   "source": [
    "### Locations\n",
    "\n",
    "Once again, it would make more sense to use a language model for this task, but since the TF-IDF cosine similarity approach performed okay with physical goods, we can definitely use it for locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93fb7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample df for locations from manually generated list\n",
    "locations = [\"LONDON\", \"HONG KONG\", \"ASIA\", \"LONDON, ENG\", \"LONDON, GREAT BRITAIN\", \"LONDON, ENGLAND\"]\n",
    "df_locations = pd.DataFrame(locations, columns=['locations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc72a1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LONDON, ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LONDON, GREAT BRITAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LONDON, ENGLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               locations\n",
       "0                 LONDON\n",
       "1              HONG KONG\n",
       "2                   ASIA\n",
       "3            LONDON, ENG\n",
       "4  LONDON, GREAT BRITAIN\n",
       "5        LONDON, ENGLAND"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6036ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function for dataframe of locations - provide dataframe and column name for locations as input\n",
    "def preprocess_locations(dataframe, column_name):\n",
    "    clean_list = [remove_special_characters(text) for text in dataframe[column_name]] \n",
    "    clean_list = [text.lower() for text in clean_list]\n",
    "    clean_list = [text.replace('  ', ' ') for text in clean_list] # remove extra whitespaces\n",
    "    clean_list = [text.strip() for text in clean_list]\n",
    "    df_clean_locations = pd.DataFrame(np.column_stack([dataframe[column_name], clean_list]), columns=['locations', 'clean_locations'])\n",
    "    return df_clean_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f21d963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locations</th>\n",
       "      <th>clean_locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>hong kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASIA</td>\n",
       "      <td>asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LONDON, ENG</td>\n",
       "      <td>london eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LONDON, GREAT BRITAIN</td>\n",
       "      <td>london great britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LONDON, ENGLAND</td>\n",
       "      <td>london england</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               locations       clean_locations\n",
       "0                 LONDON                london\n",
       "1              HONG KONG             hong kong\n",
       "2                   ASIA                  asia\n",
       "3            LONDON, ENG            london eng\n",
       "4  LONDON, GREAT BRITAIN  london great britain\n",
       "5        LONDON, ENGLAND        london england"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locations_cleaned = preprocess_locations(df_locations, 'locations'); df_locations_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bf4bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity matching function for dataframe created at preprocessing stage - provide dataframe and original column name for locations\n",
    "def entity_matcher_locations(dataframe, column_name):\n",
    "    # group entities using tf-idf to calculate cosine similarities - look for 30% minimum similarity\n",
    "    dataframe[['unique_entity_ID', 'unique_entity']] = group_similar_strings(dataframe['clean_locations'], min_similarity = 0.3)\n",
    "    dataframe = dataframe.groupby(['unique_entity_ID', 'unique_entity'])[column_name].apply('; '.join).reset_index()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1c1fafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>london</td>\n",
       "      <td>LONDON; LONDON, ENG; LONDON, GREAT BRITAIN; LO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hong kong</td>\n",
       "      <td>HONG KONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asia</td>\n",
       "      <td>ASIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID unique_entity  \\\n",
       "0                 0        london   \n",
       "1                 1     hong kong   \n",
       "2                 2          asia   \n",
       "\n",
       "                                           locations  \n",
       "0  LONDON; LONDON, ENG; LONDON, GREAT BRITAIN; LO...  \n",
       "1                                          HONG KONG  \n",
       "2                                               ASIA  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_entities_locations = entity_matcher_locations(df_locations_cleaned, 'locations'); df_unique_entities_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed147d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for processing df of locations and clustering them using string similarity\n",
    "def clustering_locations(dataframe, column_name):\n",
    "    # preprocess dataframe\n",
    "    df_locations_cleaned = preprocess_locations(dataframe, column_name)\n",
    "    # start clustering of locations\n",
    "    print('Entity clustering will start now.')\n",
    "    start = time.time()\n",
    "    df_unique_entities_locations = entity_matcher_locations(df_locations_cleaned, column_name)\n",
    "    time.sleep(1)\n",
    "    end = time.time()\n",
    "    # print total time taken\n",
    "    print(f\"Runtime of the program is {end - start} seconds.\")\n",
    "    # create csv with timestamp\n",
    "    current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = 'locations_normalized' + str(current_time) + '.csv'\n",
    "    # print job status\n",
    "    print(f\"{filename} has been saved in current directory.\")\n",
    "    return df_unique_entities_locations.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaa11b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity clustering will start now.\n",
      "Runtime of the program is 1.0146229267120361 seconds.\n",
      "locations_normalized20210725-235520.csv has been saved in current directory.\n"
     ]
    }
   ],
   "source": [
    "clustering_locations(df_locations, 'locations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91148fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>london</td>\n",
       "      <td>LONDON; LONDON, ENG; LONDON, GREAT BRITAIN; LO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hong kong</td>\n",
       "      <td>HONG KONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asia</td>\n",
       "      <td>ASIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID unique_entity  \\\n",
       "0                 0        london   \n",
       "1                 1     hong kong   \n",
       "2                 2          asia   \n",
       "\n",
       "                                           locations  \n",
       "0  LONDON; LONDON, ENG; LONDON, GREAT BRITAIN; LO...  \n",
       "1                                          HONG KONG  \n",
       "2                                               ASIA  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect results\n",
    "pd.read_csv('locations_normalized20210725-235520.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6228728c",
   "metadata": {},
   "source": [
    "### Company Names\n",
    "\n",
    "The approach we used for all categories could probably work for company names, but it could be interesting to try out something that I think could work quite well for company names: scraping the first link that comes up when performing a google search for each company name we have. We can compare this with the approach we used until now and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f20bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "\"Marks and Spencers Ltd\", \n",
    "\"M&S Limited\",\n",
    "\"NVIDIA Ireland\",\n",
    "\"Intel LLC\",\n",
    "\"AT & T\",\n",
    "\"AT & T MOBILITY\",\n",
    "\"AT&T\",\n",
    "\"AT&T MOBILITY\",\n",
    "\"DELL INC.\",\n",
    "\"WAL-MART COMMUNITY\",\n",
    "\"WALMART PAYMENTS\",\n",
    "\"PITNEY BOWES\",\n",
    "\"PITNEY BOWES GLOBAL FINANCIAL\",\n",
    "\"PITNEY BOWES, INC\",\n",
    "\"ORACLE\", \n",
    "\"ORACLE AMERICA INC\", \n",
    "\"ORACLE CORPORATION\", \n",
    "\"ORACLE USA INC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "661d44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.DataFrame(names, columns=['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9385e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "    \n",
    "# preprocess function for dataframe of locations - provide dataframe and column name for locations as input\n",
    "def google_names(dataframe, column_name):\n",
    "    clean_list = [list(search(text, tld=\"com\", num=1, stop=1, pause=0.1))[0] for text in dataframe[column_name]] \n",
    "    df_clean_names = pd.DataFrame(np.column_stack([dataframe[column_name], clean_list]), columns=['comp_names', 'google_comp_names'])\n",
    "    return df_clean_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84ad7b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_names</th>\n",
       "      <th>google_comp_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marks and Spencers Ltd</td>\n",
       "      <td>https://www.marksandspencer.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M&amp;S Limited</td>\n",
       "      <td>https://www.marksandspencer.com/ie/l/women/lim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVIDIA Ireland</td>\n",
       "      <td>https://shop.nvidia.com/en-us/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intel LLC</td>\n",
       "      <td>https://software.intel.com/content/www/us/en/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT &amp; T</td>\n",
       "      <td>https://www.att.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AT &amp; T MOBILITY</td>\n",
       "      <td>https://www.att.com/wireless/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>https://www.att.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AT&amp;T MOBILITY</td>\n",
       "      <td>https://www.att.com/wireless/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DELL INC.</td>\n",
       "      <td>https://www.dell.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WAL-MART COMMUNITY</td>\n",
       "      <td>https://walmart.org/what-we-do/strengthening-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WALMART PAYMENTS</td>\n",
       "      <td>https://www.walmart.com/cp/walmart-pay/3205993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PITNEY BOWES</td>\n",
       "      <td>https://www.pitneybowes.com/us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PITNEY BOWES GLOBAL FINANCIAL</td>\n",
       "      <td>https://www.pitneybowes.com/us/financial-servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PITNEY BOWES, INC</td>\n",
       "      <td>https://www.pitneybowes.com/us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORACLE</td>\n",
       "      <td>https://www.oracle.com/index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORACLE AMERICA INC</td>\n",
       "      <td>https://www.oracle.com/corporate/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ORACLE CORPORATION</td>\n",
       "      <td>https://commons.wikimedia.org/wiki/File:Logo_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ORACLE USA INC</td>\n",
       "      <td>https://www.oracle.com/corporate/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       comp_names  \\\n",
       "0          Marks and Spencers Ltd   \n",
       "1                     M&S Limited   \n",
       "2                  NVIDIA Ireland   \n",
       "3                       Intel LLC   \n",
       "4                          AT & T   \n",
       "5                 AT & T MOBILITY   \n",
       "6                            AT&T   \n",
       "7                   AT&T MOBILITY   \n",
       "8                       DELL INC.   \n",
       "9              WAL-MART COMMUNITY   \n",
       "10               WALMART PAYMENTS   \n",
       "11                   PITNEY BOWES   \n",
       "12  PITNEY BOWES GLOBAL FINANCIAL   \n",
       "13              PITNEY BOWES, INC   \n",
       "14                         ORACLE   \n",
       "15             ORACLE AMERICA INC   \n",
       "16             ORACLE CORPORATION   \n",
       "17                 ORACLE USA INC   \n",
       "\n",
       "                                    google_comp_names  \n",
       "0                    https://www.marksandspencer.com/  \n",
       "1   https://www.marksandspencer.com/ie/l/women/lim...  \n",
       "2                      https://shop.nvidia.com/en-us/  \n",
       "3   https://software.intel.com/content/www/us/en/d...  \n",
       "4                                https://www.att.com/  \n",
       "5                       https://www.att.com/wireless/  \n",
       "6                                https://www.att.com/  \n",
       "7                       https://www.att.com/wireless/  \n",
       "8                               https://www.dell.com/  \n",
       "9   https://walmart.org/what-we-do/strengthening-c...  \n",
       "10     https://www.walmart.com/cp/walmart-pay/3205993  \n",
       "11                     https://www.pitneybowes.com/us  \n",
       "12  https://www.pitneybowes.com/us/financial-servi...  \n",
       "13                     https://www.pitneybowes.com/us  \n",
       "14                  https://www.oracle.com/index.html  \n",
       "15                  https://www.oracle.com/corporate/  \n",
       "16  https://commons.wikimedia.org/wiki/File:Logo_o...  \n",
       "17                  https://www.oracle.com/corporate/  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names_cleaned = google_names(df_names, 'names'); df_names_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda1341",
   "metadata": {},
   "source": [
    "This approach is not giving great results and most of all it's extremely slow. It might be better to revert back to the original idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e902be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.DataFrame(names, columns=['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bc1b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanco import cleanco\n",
    "\n",
    "# preprocess function for dataframe of names - provide dataframe and column name for names as input\n",
    "def preprocess_names(dataframe, column_name):\n",
    "    clean_list = [remove_special_characters(text) for text in dataframe[column_name]] \n",
    "    clean_list = [text.lower() for text in clean_list]\n",
    "    clean_list = [text.replace('  ', ' ') for text in clean_list] # remove extra whitespaces\n",
    "    clean_list = [text.strip() for text in clean_list]\n",
    "    clean_list = [cleanco(text).clean_name() for text in clean_list] # remove legal control terms\n",
    "    df_clean_names = pd.DataFrame(np.column_stack([dataframe[column_name], clean_list]), columns=['names', 'clean_names'])\n",
    "    return df_clean_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "733b3e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>clean_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marks and Spencers Ltd</td>\n",
       "      <td>marks and spencers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M&amp;S Limited</td>\n",
       "      <td>ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVIDIA Ireland</td>\n",
       "      <td>nvidia ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intel LLC</td>\n",
       "      <td>intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT &amp; T</td>\n",
       "      <td>at t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AT &amp; T MOBILITY</td>\n",
       "      <td>at t mobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>att</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AT&amp;T MOBILITY</td>\n",
       "      <td>att mobility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DELL INC.</td>\n",
       "      <td>dell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WAL-MART COMMUNITY</td>\n",
       "      <td>walmart community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WALMART PAYMENTS</td>\n",
       "      <td>walmart payments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PITNEY BOWES</td>\n",
       "      <td>pitney bowes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PITNEY BOWES GLOBAL FINANCIAL</td>\n",
       "      <td>pitney bowes global financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PITNEY BOWES, INC</td>\n",
       "      <td>pitney bowes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORACLE</td>\n",
       "      <td>oracle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORACLE AMERICA INC</td>\n",
       "      <td>oracle america</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ORACLE CORPORATION</td>\n",
       "      <td>oracle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ORACLE USA INC</td>\n",
       "      <td>oracle usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            names                    clean_names\n",
       "0          Marks and Spencers Ltd             marks and spencers\n",
       "1                     M&S Limited                             ms\n",
       "2                  NVIDIA Ireland                 nvidia ireland\n",
       "3                       Intel LLC                          intel\n",
       "4                          AT & T                           at t\n",
       "5                 AT & T MOBILITY                  at t mobility\n",
       "6                            AT&T                            att\n",
       "7                   AT&T MOBILITY                   att mobility\n",
       "8                       DELL INC.                           dell\n",
       "9              WAL-MART COMMUNITY              walmart community\n",
       "10               WALMART PAYMENTS               walmart payments\n",
       "11                   PITNEY BOWES                   pitney bowes\n",
       "12  PITNEY BOWES GLOBAL FINANCIAL  pitney bowes global financial\n",
       "13              PITNEY BOWES, INC                   pitney bowes\n",
       "14                         ORACLE                         oracle\n",
       "15             ORACLE AMERICA INC                 oracle america\n",
       "16             ORACLE CORPORATION                         oracle\n",
       "17                 ORACLE USA INC                     oracle usa"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names_cleaned = preprocess_names(df_names, 'names'); df_names_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85f70ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity matching function for dataframe created at preprocessing stage - provide dataframe and original column name for names\n",
    "def entity_matcher_names(dataframe, column_name):\n",
    "    # group entities using tf-idf to calculate cosine similarities - look for 20% minimum similarity\n",
    "    dataframe[['unique_entity_ID', 'unique_entity']] = group_similar_strings(dataframe['clean_names'], min_similarity = 0.2)\n",
    "    dataframe = dataframe.groupby(['unique_entity_ID', 'unique_entity'])[column_name].apply('; '.join).reset_index()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48ea7722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>marks and spencers</td>\n",
       "      <td>Marks and Spencers Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ms</td>\n",
       "      <td>M&amp;S Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>nvidia ireland</td>\n",
       "      <td>NVIDIA Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>intel</td>\n",
       "      <td>Intel LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>at t</td>\n",
       "      <td>AT &amp; T; AT &amp; T MOBILITY; AT&amp;T; AT&amp;T MOBILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>dell</td>\n",
       "      <td>DELL INC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>walmart community</td>\n",
       "      <td>WAL-MART COMMUNITY; WALMART PAYMENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>pitney bowes</td>\n",
       "      <td>PITNEY BOWES; PITNEY BOWES GLOBAL FINANCIAL; P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>oracle</td>\n",
       "      <td>ORACLE; ORACLE AMERICA INC; ORACLE CORPORATION...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID       unique_entity  \\\n",
       "0                 0  marks and spencers   \n",
       "1                 1                  ms   \n",
       "2                 2      nvidia ireland   \n",
       "3                 3               intel   \n",
       "4                 4                at t   \n",
       "5                 8                dell   \n",
       "6                 9   walmart community   \n",
       "7                11        pitney bowes   \n",
       "8                14              oracle   \n",
       "\n",
       "                                               names  \n",
       "0                             Marks and Spencers Ltd  \n",
       "1                                        M&S Limited  \n",
       "2                                     NVIDIA Ireland  \n",
       "3                                          Intel LLC  \n",
       "4       AT & T; AT & T MOBILITY; AT&T; AT&T MOBILITY  \n",
       "5                                          DELL INC.  \n",
       "6               WAL-MART COMMUNITY; WALMART PAYMENTS  \n",
       "7  PITNEY BOWES; PITNEY BOWES GLOBAL FINANCIAL; P...  \n",
       "8  ORACLE; ORACLE AMERICA INC; ORACLE CORPORATION...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_entities_names = entity_matcher_names(df_names_cleaned, 'names'); df_unique_entities_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a19d0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for processing df of names and clustering them using string similarity\n",
    "def clustering_names(dataframe, column_name):\n",
    "    # preprocess dataframe\n",
    "    df_names_cleaned = preprocess_names(dataframe, column_name)\n",
    "    # start clustering of names\n",
    "    print('Entity clustering will start now.')\n",
    "    start = time.time()\n",
    "    df_unique_entities_names = entity_matcher_names(df_names_cleaned, column_name)\n",
    "    time.sleep(1)\n",
    "    end = time.time()\n",
    "    # print total time taken\n",
    "    print(f\"Runtime of the program is {end - start} seconds.\")\n",
    "    # create csv with timestamp\n",
    "    current_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = 'names_normalized' + str(current_time) + '.csv'\n",
    "    # print job status\n",
    "    print(f\"{filename} has been saved in current directory.\")\n",
    "    return df_unique_entities_names.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82494957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity clustering will start now.\n",
      "Runtime of the program is 1.016322135925293 seconds.\n",
      "names_normalized20210725-235626.csv has been saved in current directory.\n"
     ]
    }
   ],
   "source": [
    "clustering_names(df_names, 'names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ee98c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_entity_ID</th>\n",
       "      <th>unique_entity</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>marks and spencers</td>\n",
       "      <td>Marks and Spencers Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ms</td>\n",
       "      <td>M&amp;S Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>nvidia ireland</td>\n",
       "      <td>NVIDIA Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>intel</td>\n",
       "      <td>Intel LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>at t</td>\n",
       "      <td>AT &amp; T; AT &amp; T MOBILITY; AT&amp;T; AT&amp;T MOBILITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>dell</td>\n",
       "      <td>DELL INC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>walmart community</td>\n",
       "      <td>WAL-MART COMMUNITY; WALMART PAYMENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>pitney bowes</td>\n",
       "      <td>PITNEY BOWES; PITNEY BOWES GLOBAL FINANCIAL; P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>oracle</td>\n",
       "      <td>ORACLE; ORACLE AMERICA INC; ORACLE CORPORATION...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_entity_ID       unique_entity  \\\n",
       "0                 0  marks and spencers   \n",
       "1                 1                  ms   \n",
       "2                 2      nvidia ireland   \n",
       "3                 3               intel   \n",
       "4                 4                at t   \n",
       "5                 8                dell   \n",
       "6                 9   walmart community   \n",
       "7                11        pitney bowes   \n",
       "8                14              oracle   \n",
       "\n",
       "                                               names  \n",
       "0                             Marks and Spencers Ltd  \n",
       "1                                        M&S Limited  \n",
       "2                                     NVIDIA Ireland  \n",
       "3                                          Intel LLC  \n",
       "4       AT & T; AT & T MOBILITY; AT&T; AT&T MOBILITY  \n",
       "5                                          DELL INC.  \n",
       "6               WAL-MART COMMUNITY; WALMART PAYMENTS  \n",
       "7  PITNEY BOWES; PITNEY BOWES GLOBAL FINANCIAL; P...  \n",
       "8  ORACLE; ORACLE AMERICA INC; ORACLE CORPORATION...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect results\n",
    "pd.read_csv('names_normalized20210725-235626.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf7517b",
   "metadata": {},
   "source": [
    "We got issues with M&S Limited unfortunately. In this particular case, the google search scraped link would have performed better than the approach we decided to go with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3763e778",
   "metadata": {},
   "source": [
    "## Part 2: General Normalization Engine\n",
    "\n",
    "My first thought in this part was to use the approach outlined in part 1, with the addition of Named Entity Recognition (NER) right after the text pre-processing step. This would allow to separate all strings into their respective categories (serial numbers, physical goods, locations, company addresses, company names) and would allow us to use the category-specific normalization engines that were built in part 1. The issues are that NER works best when words have a context within a sentence and entity types such as serial numbers and addresses would have to be custom-trained. We would also still be relying on the rule-based cleaning engines developed in part 1 instead of making use of intelligent systems.\n",
    "\n",
    "In thinking about a solution, I think it could be interesting to explore NER with the spaCy library. An [open-source annotation tool](https://github.com/ManivannanMurugavel/spacy-ner-annotator) can be used to create a dataset that we could use to fine-tune a spaCy NER model. When I say fine-tuning, there are 2 possibilities that both seem like risky hacks: \n",
    "\n",
    "Option 1 - Creating new, custom entity types for the entities that don't yet have an entity type (serial number, address, physical goods) and updating a model with these new types. The obvious risk is that we will be run into issues of conflicting entity types. For example ADDRESS vs LOCATION.\n",
    "\n",
    "Option 2 - This one sounds quite ridiculous. We do not create custom entity types and instead train the model to recognize serial numbers as persons (PER) for example, making sure each category (serial numbers, physical goods, locations, company addresses, company names) have a unique entity type to categorize them.\n",
    "\n",
    "We could also decide to not fine tune and instead start with a blank model and teach it new entity types. Beyond this NER task, we need to start thinking about alternatives to the rule-based cleaning engines. \n",
    "\n",
    "Other ideas to explore:\n",
    "\n",
    "- Try brute-force approach of grouping all entities, completely ignoring semantics. This will give us a baseline of the performance to beat\n",
    "- Explore use of Flair library for NER, confidence score is a feature that could be useful.\n",
    "- [Wikipedia paragraph classification](https://github.com/yashsmehta/named-entity-normalization): Scrape a paragraph from wikipedia describing the entity in question, pass the paragraph through a language model (ie: BERT), feed embedding vector to a shallow classifier to make the prediction of what entity class the new entity belongs to. Could use fastai library for super quick setup/execution.\n",
    "- Re-explore clustering-based methods for entity normalization.\n",
    "- Explore viability of Named Entity Linking using Facebook's BLINK library or spaCy.\n",
    "- Create large dataset for all categories, assemble from all datasets found online so far.\n",
    "- Dealing with incoming strings: seems like the current approach will hold up with incoming strings, shouldn't worry too much about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f939b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
